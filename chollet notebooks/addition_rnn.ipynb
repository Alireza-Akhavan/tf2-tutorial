{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "addition_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mrjD9nFUI7k",
        "colab_type": "text"
      },
      "source": [
        "# An implementation of sequence to sequence learning for performing addition\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this example, we train a model to learn to add two numbers, provided as strings.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "- Input: \"535+61\"\n",
        "- Output: \"596\"\n",
        "\n",
        "Input may optionally be reversed, which was shown to increase performance in many tasks in: [Learning to Execute](http://arxiv.org/abs/1410.4615) and\n",
        "[Sequence to Sequence Learning with Neural Networks](\n",
        "  http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)\n",
        "\n",
        "Theoretically, sequence order inversion introduces shorter term dependencies between source and target for this problem.\n",
        "\n",
        "**Results:**\n",
        "\n",
        "For two digits (reversed):\n",
        "\n",
        "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
        "\n",
        "Three digits (reversed):\n",
        "\n",
        "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
        "\n",
        "Four digits (reversed):\n",
        "\n",
        "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
        "\n",
        "Five digits (reversed):\n",
        "\n",
        "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1Ohfs8qnJgh",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gWDMvELUzrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# Parameters for the model and dataset.\n",
        "TRAINING_SIZE = 50000\n",
        "DIGITS = 3\n",
        "REVERSE = True\n",
        "\n",
        "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
        "# int is DIGITS.\n",
        "MAXLEN = DIGITS + 1 + DIGITS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqdlZlK1nY3s",
        "colab_type": "text"
      },
      "source": [
        "## Generate the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHOXdH9ZnT1A",
        "colab_type": "code",
        "outputId": "ffe4baf4-51de-43fe-a8df-9fc826ec1e7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "class CharacterTable:\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one-hot integer representation\n",
        "    + Decode the one-hot or integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"Initialize character table.\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"One-hot encode given string C.\n",
        "        # Arguments\n",
        "            C: string, to be encoded.\n",
        "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        \"\"\"Decode the given vector or 2D array to their character output.\n",
        "        # Arguments\n",
        "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
        "                or a vector of character indices (used with `calc_argmax=False`).\n",
        "            calc_argmax: Whether to find the character index with maximum\n",
        "                probability, defaults to `True`.\n",
        "        \"\"\"\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return ''.join(self.indices_char[x] for x in x)\n",
        "\n",
        "# All the numbers, plus sign and space for padding.\n",
        "chars = '0123456789+ '\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print('Generating data...')\n",
        "while len(questions) < TRAINING_SIZE:\n",
        "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
        "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
        "    a, b = f(), f()\n",
        "    # Skip any addition questions we've already seen\n",
        "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    # Pad the data with spaces such that it is always MAXLEN.\n",
        "    q = '{}+{}'.format(a, b)\n",
        "    query = q + ' ' * (MAXLEN - len(q))\n",
        "    ans = str(a + b)\n",
        "    # Answers can be of maximum size DIGITS + 1.\n",
        "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
        "    if REVERSE:\n",
        "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
        "        # space used for padding.)\n",
        "        query = query[::-1]\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "print('Total questions:', len(questions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating data...\n",
            "Total questions: 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrilR3gPn3Nv",
        "colab_type": "text"
      },
      "source": [
        "## Vectorize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbsRlbgkn4nW",
        "colab_type": "code",
        "outputId": "e3e0d581-8b5a-451d-b09b-9d5a6aff0568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "print('Vectorization...')\n",
        "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, MAXLEN)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
        "\n",
        "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
        "# digits.\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# Explicitly set apart 10% for validation data that we never train over.\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "print('Training Data:')\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print('Validation Data:')\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorization...\n",
            "Training Data:\n",
            "(45000, 7, 12)\n",
            "(45000, 4, 12)\n",
            "Validation Data:\n",
            "(5000, 7, 12)\n",
            "(5000, 4, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7v_aoIvn_vv",
        "colab_type": "text"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka-W5x9ToBnM",
        "colab_type": "code",
        "outputId": "ede0ba1b-0715-4977-ea06-dfa97b64f8a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "print('Build model...')\n",
        "num_layers = 1  # Try to add more LSTM layers!\n",
        "\n",
        "model = keras.Sequential()\n",
        "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
        "# Note: In a situation where your input sequences have a variable length,\n",
        "# use input_shape=(None, num_feature).\n",
        "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
        "# As the decoder RNN's input, repeatedly provide with the last output of\n",
        "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
        "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "# The decoder RNN could be multiple layers stacked or a single layer.\n",
        "for _ in range(num_layers):\n",
        "    # By setting return_sequences to True, return not only the last output but\n",
        "    # all the outputs so far in the form of (num_samples, timesteps,\n",
        "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
        "    # the first dimension to be the timesteps.\n",
        "    model.add(layers.LSTM(128, return_sequences=True))\n",
        "\n",
        "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
        "# of the output sequence, decide which character should be chosen.\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               72192     \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 4, 128)            131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4, 12)             1548      \n",
            "=================================================================\n",
            "Total params: 205,324\n",
            "Trainable params: 205,324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfCPVEyKopik",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKdZkFIkobEQ",
        "colab_type": "code",
        "outputId": "3cf04497-937d-4e16-86a2-fd2e51809876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# To shorten execution time, we only train for 5 epochs.\n",
        "# In practice, you will need at least ~30 epochs\n",
        "epochs = 5\n",
        "batch_size = 32\n",
        "\n",
        "# For colorful logging.\n",
        "class colors:\n",
        "    ok = '\\033[92m'\n",
        "    fail = '\\033[91m'\n",
        "    close = '\\033[0m'\n",
        "\n",
        "# Train the model each generation and show predictions against the validation\n",
        "# dataset.\n",
        "for epoch in range(1, epochs):\n",
        "    print()\n",
        "    print('Iteration', epoch)\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=1,\n",
        "              validation_data=(x_val, y_val))\n",
        "    # Select 10 samples from the validation set at random so we can visualize\n",
        "    # errors.\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
        "        print('T', correct, end=' ')\n",
        "        if correct == guess:\n",
        "            print(colors.ok + '☑' + colors.close, end=' ')\n",
        "        else:\n",
        "            print(colors.fail + '☒' + colors.close, end=' ')\n",
        "        print(guess)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 1\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7608 - accuracy: 0.3544 - val_loss: 1.6119 - val_accuracy: 0.3979\n",
            "Q 9+440   T 449  \u001b[91m☒\u001b[0m 144 \n",
            "Q 22+63   T 85   \u001b[91m☒\u001b[0m 222 \n",
            "Q 675+505 T 1180 \u001b[91m☒\u001b[0m 1322\n",
            "Q 789+88  T 877  \u001b[91m☒\u001b[0m 902 \n",
            "Q 705+13  T 718  \u001b[91m☒\u001b[0m 762 \n",
            "Q 481+250 T 731  \u001b[91m☒\u001b[0m 802 \n",
            "Q 94+86   T 180  \u001b[91m☒\u001b[0m 104 \n",
            "Q 226+1   T 227  \u001b[91m☒\u001b[0m 222 \n",
            "Q 83+290  T 373  \u001b[91m☒\u001b[0m 222 \n",
            "Q 537+84  T 621  \u001b[91m☒\u001b[0m 802 \n",
            "\n",
            "Iteration 2\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3825 - accuracy: 0.4818 - val_loss: 1.1866 - val_accuracy: 0.5519\n",
            "Q 221+43  T 264  \u001b[91m☒\u001b[0m 274 \n",
            "Q 485+503 T 988  \u001b[91m☒\u001b[0m 100 \n",
            "Q 480+184 T 664  \u001b[91m☒\u001b[0m 542 \n",
            "Q 246+180 T 426  \u001b[91m☒\u001b[0m 442 \n",
            "Q 787+15  T 802  \u001b[91m☒\u001b[0m 899 \n",
            "Q 52+42   T 94   \u001b[91m☒\u001b[0m 10  \n",
            "Q 794+3   T 797  \u001b[91m☒\u001b[0m 890 \n",
            "Q 390+2   T 392  \u001b[91m☒\u001b[0m 390 \n",
            "Q 836+95  T 931  \u001b[91m☒\u001b[0m 941 \n",
            "Q 157+92  T 249  \u001b[91m☒\u001b[0m 229 \n",
            "\n",
            "Iteration 3\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0398 - accuracy: 0.6149 - val_loss: 0.9758 - val_accuracy: 0.6319\n",
            "Q 58+770  T 828  \u001b[91m☒\u001b[0m 824 \n",
            "Q 527+23  T 550  \u001b[91m☒\u001b[0m 551 \n",
            "Q 76+692  T 768  \u001b[91m☒\u001b[0m 760 \n",
            "Q 294+33  T 327  \u001b[91m☒\u001b[0m 321 \n",
            "Q 43+735  T 778  \u001b[91m☒\u001b[0m 789 \n",
            "Q 688+83  T 771  \u001b[91m☒\u001b[0m 769 \n",
            "Q 934+672 T 1606 \u001b[91m☒\u001b[0m 1512\n",
            "Q 683+5   T 688  \u001b[91m☒\u001b[0m 692 \n",
            "Q 699+752 T 1451 \u001b[91m☒\u001b[0m 1442\n",
            "Q 362+243 T 605  \u001b[91m☒\u001b[0m 611 \n",
            "\n",
            "Iteration 4\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.8745 - accuracy: 0.6778 - val_loss: 0.8180 - val_accuracy: 0.6971\n",
            "Q 640+27  T 667  \u001b[91m☒\u001b[0m 661 \n",
            "Q 869+57  T 926  \u001b[91m☒\u001b[0m 934 \n",
            "Q 32+46   T 78   \u001b[91m☒\u001b[0m 84  \n",
            "Q 8+543   T 551  \u001b[91m☒\u001b[0m 554 \n",
            "Q 789+24  T 813  \u001b[91m☒\u001b[0m 814 \n",
            "Q 7+980   T 987  \u001b[91m☒\u001b[0m 985 \n",
            "Q 347+56  T 403  \u001b[91m☒\u001b[0m 404 \n",
            "Q 7+755   T 762  \u001b[92m☑\u001b[0m 762 \n",
            "Q 0+541   T 541  \u001b[91m☒\u001b[0m 543 \n",
            "Q 727+90  T 817  \u001b[91m☒\u001b[0m 814 \n",
            "\n",
            "Iteration 5\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.7738 - accuracy: 0.7152 - val_loss: 0.7552 - val_accuracy: 0.7201\n",
            "Q 0+361   T 361  \u001b[91m☒\u001b[0m 366 \n",
            "Q 60+517  T 577  \u001b[91m☒\u001b[0m 576 \n",
            "Q 25+249  T 274  \u001b[91m☒\u001b[0m 271 \n",
            "Q 62+950  T 1012 \u001b[91m☒\u001b[0m 1016\n",
            "Q 9+801   T 810  \u001b[91m☒\u001b[0m 819 \n",
            "Q 76+105  T 181  \u001b[91m☒\u001b[0m 179 \n",
            "Q 453+412 T 865  \u001b[91m☒\u001b[0m 866 \n",
            "Q 397+685 T 1082 \u001b[91m☒\u001b[0m 1076\n",
            "Q 6+819   T 825  \u001b[91m☒\u001b[0m 823 \n",
            "Q 92+556  T 648  \u001b[91m☒\u001b[0m 643 \n",
            "\n",
            "Iteration 6\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.6946 - accuracy: 0.7467 - val_loss: 0.6674 - val_accuracy: 0.7556\n",
            "Q 167+246 T 413  \u001b[92m☑\u001b[0m 413 \n",
            "Q 600+75  T 675  \u001b[91m☒\u001b[0m 676 \n",
            "Q 773+4   T 777  \u001b[92m☑\u001b[0m 777 \n",
            "Q 851+741 T 1592 \u001b[91m☒\u001b[0m 1596\n",
            "Q 21+329  T 350  \u001b[91m☒\u001b[0m 358 \n",
            "Q 86+671  T 757  \u001b[91m☒\u001b[0m 753 \n",
            "Q 864+5   T 869  \u001b[92m☑\u001b[0m 869 \n",
            "Q 77+912  T 989  \u001b[91m☒\u001b[0m 998 \n",
            "Q 421+137 T 558  \u001b[91m☒\u001b[0m 551 \n",
            "Q 4+689   T 693  \u001b[91m☒\u001b[0m 692 \n",
            "\n",
            "Iteration 7\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.6143 - accuracy: 0.7776 - val_loss: 0.5632 - val_accuracy: 0.7940\n",
            "Q 7+740   T 747  \u001b[91m☒\u001b[0m 748 \n",
            "Q 77+929  T 1006 \u001b[91m☒\u001b[0m 1016\n",
            "Q 493+98  T 591  \u001b[91m☒\u001b[0m 583 \n",
            "Q 0+100   T 100  \u001b[91m☒\u001b[0m 101 \n",
            "Q 843+67  T 910  \u001b[91m☒\u001b[0m 911 \n",
            "Q 282+54  T 336  \u001b[91m☒\u001b[0m 338 \n",
            "Q 440+921 T 1361 \u001b[91m☒\u001b[0m 1353\n",
            "Q 911+952 T 1863 \u001b[91m☒\u001b[0m 1866\n",
            "Q 65+75   T 140  \u001b[92m☑\u001b[0m 140 \n",
            "Q 978+322 T 1300 \u001b[91m☒\u001b[0m 1306\n",
            "\n",
            "Iteration 8\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4302 - accuracy: 0.8481 - val_loss: 0.3582 - val_accuracy: 0.8773\n",
            "Q 405+27  T 432  \u001b[92m☑\u001b[0m 432 \n",
            "Q 7+306   T 313  \u001b[91m☒\u001b[0m 312 \n",
            "Q 6+386   T 392  \u001b[92m☑\u001b[0m 392 \n",
            "Q 31+555  T 586  \u001b[92m☑\u001b[0m 586 \n",
            "Q 769+110 T 879  \u001b[92m☑\u001b[0m 879 \n",
            "Q 722+60  T 782  \u001b[92m☑\u001b[0m 782 \n",
            "Q 630+454 T 1084 \u001b[92m☑\u001b[0m 1084\n",
            "Q 974+93  T 1067 \u001b[92m☑\u001b[0m 1067\n",
            "Q 647+169 T 816  \u001b[91m☒\u001b[0m 805 \n",
            "Q 573+350 T 923  \u001b[91m☒\u001b[0m 924 \n",
            "\n",
            "Iteration 9\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.2339 - accuracy: 0.9352 - val_loss: 0.2997 - val_accuracy: 0.9082\n",
            "Q 830+690 T 1520 \u001b[91m☒\u001b[0m 1532\n",
            "Q 48+43   T 91   \u001b[91m☒\u001b[0m 90  \n",
            "Q 97+189  T 286  \u001b[92m☑\u001b[0m 286 \n",
            "Q 47+44   T 91   \u001b[91m☒\u001b[0m 90  \n",
            "Q 11+130  T 141  \u001b[91m☒\u001b[0m 13  \n",
            "Q 99+901  T 1000 \u001b[91m☒\u001b[0m 900 \n",
            "Q 2+421   T 423  \u001b[92m☑\u001b[0m 423 \n",
            "Q 7+306   T 313  \u001b[91m☒\u001b[0m 312 \n",
            "Q 55+891  T 946  \u001b[92m☑\u001b[0m 946 \n",
            "Q 51+80   T 131  \u001b[91m☒\u001b[0m 132 \n",
            "\n",
            "Iteration 10\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.1427 - accuracy: 0.9661 - val_loss: 0.1302 - val_accuracy: 0.9667\n",
            "Q 527+67  T 594  \u001b[92m☑\u001b[0m 594 \n",
            "Q 36+58   T 94   \u001b[92m☑\u001b[0m 94  \n",
            "Q 401+89  T 490  \u001b[92m☑\u001b[0m 490 \n",
            "Q 551+25  T 576  \u001b[92m☑\u001b[0m 576 \n",
            "Q 31+802  T 833  \u001b[91m☒\u001b[0m 834 \n",
            "Q 18+115  T 133  \u001b[92m☑\u001b[0m 133 \n",
            "Q 305+536 T 841  \u001b[91m☒\u001b[0m 831 \n",
            "Q 2+202   T 204  \u001b[92m☑\u001b[0m 204 \n",
            "Q 313+11  T 324  \u001b[92m☑\u001b[0m 324 \n",
            "Q 1+266   T 267  \u001b[92m☑\u001b[0m 267 \n",
            "\n",
            "Iteration 11\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1031 - accuracy: 0.9749 - val_loss: 0.0915 - val_accuracy: 0.9766\n",
            "Q 425+96  T 521  \u001b[91m☒\u001b[0m 531 \n",
            "Q 25+562  T 587  \u001b[92m☑\u001b[0m 587 \n",
            "Q 9+849   T 858  \u001b[91m☒\u001b[0m 868 \n",
            "Q 962+935 T 1897 \u001b[92m☑\u001b[0m 1897\n",
            "Q 545+916 T 1461 \u001b[92m☑\u001b[0m 1461\n",
            "Q 27+401  T 428  \u001b[92m☑\u001b[0m 428 \n",
            "Q 14+442  T 456  \u001b[92m☑\u001b[0m 456 \n",
            "Q 45+649  T 694  \u001b[92m☑\u001b[0m 694 \n",
            "Q 794+70  T 864  \u001b[92m☑\u001b[0m 864 \n",
            "Q 515+65  T 580  \u001b[92m☑\u001b[0m 580 \n",
            "\n",
            "Iteration 12\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0688 - accuracy: 0.9844 - val_loss: 0.0761 - val_accuracy: 0.9786\n",
            "Q 222+669 T 891  \u001b[92m☑\u001b[0m 891 \n",
            "Q 80+347  T 427  \u001b[92m☑\u001b[0m 427 \n",
            "Q 319+966 T 1285 \u001b[92m☑\u001b[0m 1285\n",
            "Q 0+174   T 174  \u001b[92m☑\u001b[0m 174 \n",
            "Q 472+77  T 549  \u001b[92m☑\u001b[0m 549 \n",
            "Q 208+743 T 951  \u001b[92m☑\u001b[0m 951 \n",
            "Q 242+55  T 297  \u001b[92m☑\u001b[0m 297 \n",
            "Q 377+22  T 399  \u001b[92m☑\u001b[0m 399 \n",
            "Q 93+95   T 188  \u001b[92m☑\u001b[0m 188 \n",
            "Q 996+9   T 1005 \u001b[92m☑\u001b[0m 1005\n",
            "\n",
            "Iteration 13\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0569 - accuracy: 0.9863 - val_loss: 0.1595 - val_accuracy: 0.9446\n",
            "Q 995+77  T 1072 \u001b[92m☑\u001b[0m 1072\n",
            "Q 7+965   T 972  \u001b[92m☑\u001b[0m 972 \n",
            "Q 49+907  T 956  \u001b[92m☑\u001b[0m 956 \n",
            "Q 31+6    T 37   \u001b[92m☑\u001b[0m 37  \n",
            "Q 83+975  T 1058 \u001b[92m☑\u001b[0m 1058\n",
            "Q 9+470   T 479  \u001b[92m☑\u001b[0m 479 \n",
            "Q 680+90  T 770  \u001b[92m☑\u001b[0m 770 \n",
            "Q 82+24   T 106  \u001b[92m☑\u001b[0m 106 \n",
            "Q 52+964  T 1016 \u001b[92m☑\u001b[0m 1016\n",
            "Q 303+81  T 384  \u001b[91m☒\u001b[0m 385 \n",
            "\n",
            "Iteration 14\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0489 - accuracy: 0.9880 - val_loss: 0.0771 - val_accuracy: 0.9755\n",
            "Q 384+0   T 384  \u001b[92m☑\u001b[0m 384 \n",
            "Q 99+37   T 136  \u001b[92m☑\u001b[0m 136 \n",
            "Q 532+5   T 537  \u001b[92m☑\u001b[0m 537 \n",
            "Q 262+204 T 466  \u001b[92m☑\u001b[0m 466 \n",
            "Q 54+13   T 67   \u001b[92m☑\u001b[0m 67  \n",
            "Q 688+83  T 771  \u001b[92m☑\u001b[0m 771 \n",
            "Q 90+50   T 140  \u001b[92m☑\u001b[0m 140 \n",
            "Q 54+325  T 379  \u001b[92m☑\u001b[0m 379 \n",
            "Q 131+3   T 134  \u001b[92m☑\u001b[0m 134 \n",
            "Q 108+81  T 189  \u001b[92m☑\u001b[0m 189 \n",
            "\n",
            "Iteration 15\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0394 - accuracy: 0.9904 - val_loss: 0.0260 - val_accuracy: 0.9945\n",
            "Q 110+553 T 663  \u001b[92m☑\u001b[0m 663 \n",
            "Q 61+57   T 118  \u001b[92m☑\u001b[0m 118 \n",
            "Q 779+721 T 1500 \u001b[92m☑\u001b[0m 1500\n",
            "Q 902+794 T 1696 \u001b[92m☑\u001b[0m 1696\n",
            "Q 268+700 T 968  \u001b[92m☑\u001b[0m 968 \n",
            "Q 791+5   T 796  \u001b[92m☑\u001b[0m 796 \n",
            "Q 262+95  T 357  \u001b[92m☑\u001b[0m 357 \n",
            "Q 61+366  T 427  \u001b[92m☑\u001b[0m 427 \n",
            "Q 975+375 T 1350 \u001b[92m☑\u001b[0m 1350\n",
            "Q 863+77  T 940  \u001b[92m☑\u001b[0m 940 \n",
            "\n",
            "Iteration 16\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0405 - accuracy: 0.9897 - val_loss: 0.0421 - val_accuracy: 0.9885\n",
            "Q 244+8   T 252  \u001b[92m☑\u001b[0m 252 \n",
            "Q 705+5   T 710  \u001b[92m☑\u001b[0m 710 \n",
            "Q 56+41   T 97   \u001b[92m☑\u001b[0m 97  \n",
            "Q 21+23   T 44   \u001b[92m☑\u001b[0m 44  \n",
            "Q 88+450  T 538  \u001b[92m☑\u001b[0m 538 \n",
            "Q 951+43  T 994  \u001b[92m☑\u001b[0m 994 \n",
            "Q 8+817   T 825  \u001b[92m☑\u001b[0m 825 \n",
            "Q 138+85  T 223  \u001b[92m☑\u001b[0m 223 \n",
            "Q 348+859 T 1207 \u001b[92m☑\u001b[0m 1207\n",
            "Q 95+347  T 442  \u001b[92m☑\u001b[0m 442 \n",
            "\n",
            "Iteration 17\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0488 - accuracy: 0.9863 - val_loss: 0.0158 - val_accuracy: 0.9977\n",
            "Q 796+975 T 1771 \u001b[92m☑\u001b[0m 1771\n",
            "Q 895+712 T 1607 \u001b[92m☑\u001b[0m 1607\n",
            "Q 971+4   T 975  \u001b[92m☑\u001b[0m 975 \n",
            "Q 927+775 T 1702 \u001b[92m☑\u001b[0m 1702\n",
            "Q 809+850 T 1659 \u001b[92m☑\u001b[0m 1659\n",
            "Q 833+517 T 1350 \u001b[92m☑\u001b[0m 1350\n",
            "Q 999+222 T 1221 \u001b[92m☑\u001b[0m 1221\n",
            "Q 8+946   T 954  \u001b[92m☑\u001b[0m 954 \n",
            "Q 494+24  T 518  \u001b[92m☑\u001b[0m 518 \n",
            "Q 72+149  T 221  \u001b[92m☑\u001b[0m 221 \n",
            "\n",
            "Iteration 18\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0259 - accuracy: 0.9933 - val_loss: 0.0261 - val_accuracy: 0.9934\n",
            "Q 831+584 T 1415 \u001b[92m☑\u001b[0m 1415\n",
            "Q 760+4   T 764  \u001b[92m☑\u001b[0m 764 \n",
            "Q 51+60   T 111  \u001b[92m☑\u001b[0m 111 \n",
            "Q 400+63  T 463  \u001b[92m☑\u001b[0m 463 \n",
            "Q 29+44   T 73   \u001b[92m☑\u001b[0m 73  \n",
            "Q 966+529 T 1495 \u001b[92m☑\u001b[0m 1495\n",
            "Q 992+69  T 1061 \u001b[92m☑\u001b[0m 1061\n",
            "Q 685+26  T 711  \u001b[92m☑\u001b[0m 711 \n",
            "Q 652+58  T 710  \u001b[92m☑\u001b[0m 710 \n",
            "Q 17+552  T 569  \u001b[92m☑\u001b[0m 569 \n",
            "\n",
            "Iteration 19\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0202 - accuracy: 0.9953 - val_loss: 0.0952 - val_accuracy: 0.9670\n",
            "Q 359+590 T 949  \u001b[92m☑\u001b[0m 949 \n",
            "Q 987+118 T 1105 \u001b[91m☒\u001b[0m 1104\n",
            "Q 73+611  T 684  \u001b[92m☑\u001b[0m 684 \n",
            "Q 261+390 T 651  \u001b[92m☑\u001b[0m 651 \n",
            "Q 686+54  T 740  \u001b[92m☑\u001b[0m 740 \n",
            "Q 452+194 T 646  \u001b[91m☒\u001b[0m 645 \n",
            "Q 756+119 T 875  \u001b[92m☑\u001b[0m 875 \n",
            "Q 4+531   T 535  \u001b[92m☑\u001b[0m 535 \n",
            "Q 836+931 T 1767 \u001b[91m☒\u001b[0m 1757\n",
            "Q 631+994 T 1625 \u001b[92m☑\u001b[0m 1625\n",
            "\n",
            "Iteration 20\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0296 - accuracy: 0.9925 - val_loss: 0.0340 - val_accuracy: 0.9898\n",
            "Q 89+453  T 542  \u001b[92m☑\u001b[0m 542 \n",
            "Q 400+57  T 457  \u001b[92m☑\u001b[0m 457 \n",
            "Q 69+165  T 234  \u001b[92m☑\u001b[0m 234 \n",
            "Q 16+606  T 622  \u001b[92m☑\u001b[0m 622 \n",
            "Q 45+33   T 78   \u001b[92m☑\u001b[0m 78  \n",
            "Q 72+149  T 221  \u001b[92m☑\u001b[0m 221 \n",
            "Q 47+510  T 557  \u001b[91m☒\u001b[0m 567 \n",
            "Q 4+207   T 211  \u001b[92m☑\u001b[0m 211 \n",
            "Q 73+424  T 497  \u001b[92m☑\u001b[0m 497 \n",
            "Q 558+13  T 571  \u001b[92m☑\u001b[0m 571 \n",
            "\n",
            "Iteration 21\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0253 - accuracy: 0.9934 - val_loss: 0.0397 - val_accuracy: 0.9873\n",
            "Q 45+353  T 398  \u001b[92m☑\u001b[0m 398 \n",
            "Q 442+13  T 455  \u001b[92m☑\u001b[0m 455 \n",
            "Q 20+282  T 302  \u001b[91m☒\u001b[0m 202 \n",
            "Q 42+82   T 124  \u001b[92m☑\u001b[0m 124 \n",
            "Q 632+49  T 681  \u001b[92m☑\u001b[0m 681 \n",
            "Q 74+181  T 255  \u001b[92m☑\u001b[0m 255 \n",
            "Q 2+653   T 655  \u001b[92m☑\u001b[0m 655 \n",
            "Q 583+726 T 1309 \u001b[92m☑\u001b[0m 1309\n",
            "Q 931+18  T 949  \u001b[92m☑\u001b[0m 949 \n",
            "Q 311+12  T 323  \u001b[92m☑\u001b[0m 323 \n",
            "\n",
            "Iteration 22\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0271 - accuracy: 0.9929 - val_loss: 0.0081 - val_accuracy: 0.9985\n",
            "Q 459+736 T 1195 \u001b[92m☑\u001b[0m 1195\n",
            "Q 964+190 T 1154 \u001b[92m☑\u001b[0m 1154\n",
            "Q 385+86  T 471  \u001b[92m☑\u001b[0m 471 \n",
            "Q 0+163   T 163  \u001b[92m☑\u001b[0m 163 \n",
            "Q 802+0   T 802  \u001b[92m☑\u001b[0m 802 \n",
            "Q 37+46   T 83   \u001b[92m☑\u001b[0m 83  \n",
            "Q 215+70  T 285  \u001b[92m☑\u001b[0m 285 \n",
            "Q 95+998  T 1093 \u001b[92m☑\u001b[0m 1093\n",
            "Q 679+255 T 934  \u001b[92m☑\u001b[0m 934 \n",
            "Q 269+431 T 700  \u001b[92m☑\u001b[0m 700 \n",
            "\n",
            "Iteration 23\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0211 - accuracy: 0.9941 - val_loss: 0.0312 - val_accuracy: 0.9918\n",
            "Q 683+5   T 688  \u001b[92m☑\u001b[0m 688 \n",
            "Q 746+292 T 1038 \u001b[92m☑\u001b[0m 1038\n",
            "Q 390+836 T 1226 \u001b[92m☑\u001b[0m 1226\n",
            "Q 77+929  T 1006 \u001b[92m☑\u001b[0m 1006\n",
            "Q 28+56   T 84   \u001b[92m☑\u001b[0m 84  \n",
            "Q 681+82  T 763  \u001b[92m☑\u001b[0m 763 \n",
            "Q 724+718 T 1442 \u001b[92m☑\u001b[0m 1442\n",
            "Q 84+79   T 163  \u001b[92m☑\u001b[0m 163 \n",
            "Q 77+34   T 111  \u001b[92m☑\u001b[0m 111 \n",
            "Q 369+551 T 920  \u001b[92m☑\u001b[0m 920 \n",
            "\n",
            "Iteration 24\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0280 - accuracy: 0.9919 - val_loss: 0.0084 - val_accuracy: 0.9985\n",
            "Q 264+243 T 507  \u001b[92m☑\u001b[0m 507 \n",
            "Q 0+744   T 744  \u001b[92m☑\u001b[0m 744 \n",
            "Q 405+409 T 814  \u001b[92m☑\u001b[0m 814 \n",
            "Q 3+340   T 343  \u001b[92m☑\u001b[0m 343 \n",
            "Q 399+42  T 441  \u001b[92m☑\u001b[0m 441 \n",
            "Q 72+24   T 96   \u001b[92m☑\u001b[0m 96  \n",
            "Q 75+639  T 714  \u001b[92m☑\u001b[0m 714 \n",
            "Q 683+618 T 1301 \u001b[92m☑\u001b[0m 1301\n",
            "Q 56+349  T 405  \u001b[92m☑\u001b[0m 405 \n",
            "Q 4+153   T 157  \u001b[92m☑\u001b[0m 157 \n",
            "\n",
            "Iteration 25\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0179 - accuracy: 0.9959 - val_loss: 0.0060 - val_accuracy: 0.9988\n",
            "Q 961+186 T 1147 \u001b[92m☑\u001b[0m 1147\n",
            "Q 874+80  T 954  \u001b[92m☑\u001b[0m 954 \n",
            "Q 582+40  T 622  \u001b[92m☑\u001b[0m 622 \n",
            "Q 778+5   T 783  \u001b[92m☑\u001b[0m 783 \n",
            "Q 22+7    T 29   \u001b[92m☑\u001b[0m 29  \n",
            "Q 530+394 T 924  \u001b[92m☑\u001b[0m 924 \n",
            "Q 862+89  T 951  \u001b[92m☑\u001b[0m 951 \n",
            "Q 64+71   T 135  \u001b[92m☑\u001b[0m 135 \n",
            "Q 297+62  T 359  \u001b[92m☑\u001b[0m 359 \n",
            "Q 220+39  T 259  \u001b[92m☑\u001b[0m 259 \n",
            "\n",
            "Iteration 26\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.0084 - val_accuracy: 0.9984\n",
            "Q 647+55  T 702  \u001b[92m☑\u001b[0m 702 \n",
            "Q 436+809 T 1245 \u001b[92m☑\u001b[0m 1245\n",
            "Q 86+356  T 442  \u001b[92m☑\u001b[0m 442 \n",
            "Q 596+991 T 1587 \u001b[92m☑\u001b[0m 1587\n",
            "Q 96+109  T 205  \u001b[92m☑\u001b[0m 205 \n",
            "Q 852+2   T 854  \u001b[92m☑\u001b[0m 854 \n",
            "Q 479+72  T 551  \u001b[92m☑\u001b[0m 551 \n",
            "Q 373+582 T 955  \u001b[92m☑\u001b[0m 955 \n",
            "Q 53+214  T 267  \u001b[92m☑\u001b[0m 267 \n",
            "Q 847+66  T 913  \u001b[92m☑\u001b[0m 913 \n",
            "\n",
            "Iteration 27\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0244 - accuracy: 0.9935 - val_loss: 0.0301 - val_accuracy: 0.9907\n",
            "Q 551+25  T 576  \u001b[92m☑\u001b[0m 576 \n",
            "Q 186+687 T 873  \u001b[91m☒\u001b[0m 883 \n",
            "Q 135+621 T 756  \u001b[92m☑\u001b[0m 756 \n",
            "Q 754+62  T 816  \u001b[92m☑\u001b[0m 816 \n",
            "Q 48+897  T 945  \u001b[92m☑\u001b[0m 945 \n",
            "Q 7+598   T 605  \u001b[92m☑\u001b[0m 605 \n",
            "Q 30+270  T 300  \u001b[92m☑\u001b[0m 300 \n",
            "Q 516+839 T 1355 \u001b[92m☑\u001b[0m 1355\n",
            "Q 4+376   T 380  \u001b[92m☑\u001b[0m 380 \n",
            "Q 819+90  T 909  \u001b[92m☑\u001b[0m 909 \n",
            "\n",
            "Iteration 28\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.0055 - val_accuracy: 0.9991\n",
            "Q 870+47  T 917  \u001b[92m☑\u001b[0m 917 \n",
            "Q 651+57  T 708  \u001b[92m☑\u001b[0m 708 \n",
            "Q 31+71   T 102  \u001b[92m☑\u001b[0m 102 \n",
            "Q 754+78  T 832  \u001b[92m☑\u001b[0m 832 \n",
            "Q 508+28  T 536  \u001b[92m☑\u001b[0m 536 \n",
            "Q 3+944   T 947  \u001b[92m☑\u001b[0m 947 \n",
            "Q 69+90   T 159  \u001b[92m☑\u001b[0m 159 \n",
            "Q 701+48  T 749  \u001b[92m☑\u001b[0m 749 \n",
            "Q 364+945 T 1309 \u001b[92m☑\u001b[0m 1309\n",
            "Q 472+845 T 1317 \u001b[92m☑\u001b[0m 1317\n",
            "\n",
            "Iteration 29\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0271 - accuracy: 0.9927 - val_loss: 0.0058 - val_accuracy: 0.9990\n",
            "Q 3+921   T 924  \u001b[92m☑\u001b[0m 924 \n",
            "Q 373+13  T 386  \u001b[92m☑\u001b[0m 386 \n",
            "Q 465+958 T 1423 \u001b[92m☑\u001b[0m 1423\n",
            "Q 283+32  T 315  \u001b[92m☑\u001b[0m 315 \n",
            "Q 537+597 T 1134 \u001b[92m☑\u001b[0m 1134\n",
            "Q 615+17  T 632  \u001b[92m☑\u001b[0m 632 \n",
            "Q 50+307  T 357  \u001b[92m☑\u001b[0m 357 \n",
            "Q 69+204  T 273  \u001b[92m☑\u001b[0m 273 \n",
            "Q 69+322  T 391  \u001b[92m☑\u001b[0m 391 \n",
            "Q 192+170 T 362  \u001b[92m☑\u001b[0m 362 \n",
            "\n",
            "Iteration 30\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0204 - accuracy: 0.9947 - val_loss: 0.0112 - val_accuracy: 0.9970\n",
            "Q 675+42  T 717  \u001b[92m☑\u001b[0m 717 \n",
            "Q 552+537 T 1089 \u001b[92m☑\u001b[0m 1089\n",
            "Q 38+21   T 59   \u001b[92m☑\u001b[0m 59  \n",
            "Q 222+57  T 279  \u001b[92m☑\u001b[0m 279 \n",
            "Q 287+64  T 351  \u001b[92m☑\u001b[0m 351 \n",
            "Q 975+375 T 1350 \u001b[92m☑\u001b[0m 1350\n",
            "Q 362+29  T 391  \u001b[92m☑\u001b[0m 391 \n",
            "Q 213+69  T 282  \u001b[92m☑\u001b[0m 282 \n",
            "Q 3+573   T 576  \u001b[92m☑\u001b[0m 576 \n",
            "Q 194+57  T 251  \u001b[92m☑\u001b[0m 251 \n",
            "\n",
            "Iteration 31\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.1001 - val_accuracy: 0.9680\n",
            "Q 103+913 T 1016 \u001b[92m☑\u001b[0m 1016\n",
            "Q 781+376 T 1157 \u001b[91m☒\u001b[0m 1247\n",
            "Q 650+836 T 1486 \u001b[92m☑\u001b[0m 1486\n",
            "Q 988+19  T 1007 \u001b[92m☑\u001b[0m 1007\n",
            "Q 69+204  T 273  \u001b[92m☑\u001b[0m 273 \n",
            "Q 696+11  T 707  \u001b[92m☑\u001b[0m 707 \n",
            "Q 754+62  T 816  \u001b[92m☑\u001b[0m 816 \n",
            "Q 946+5   T 951  \u001b[92m☑\u001b[0m 951 \n",
            "Q 11+27   T 38   \u001b[92m☑\u001b[0m 38  \n",
            "Q 5+689   T 694  \u001b[92m☑\u001b[0m 694 \n",
            "\n",
            "Iteration 32\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Q 3+512   T 515  \u001b[92m☑\u001b[0m 515 \n",
            "Q 33+780  T 813  \u001b[92m☑\u001b[0m 813 \n",
            "Q 5+631   T 636  \u001b[92m☑\u001b[0m 636 \n",
            "Q 933+680 T 1613 \u001b[92m☑\u001b[0m 1613\n",
            "Q 337+611 T 948  \u001b[92m☑\u001b[0m 948 \n",
            "Q 302+197 T 499  \u001b[92m☑\u001b[0m 499 \n",
            "Q 66+389  T 455  \u001b[92m☑\u001b[0m 455 \n",
            "Q 580+2   T 582  \u001b[92m☑\u001b[0m 582 \n",
            "Q 873+497 T 1370 \u001b[92m☑\u001b[0m 1370\n",
            "Q 131+3   T 134  \u001b[92m☑\u001b[0m 134 \n",
            "\n",
            "Iteration 33\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0218 - accuracy: 0.9941 - val_loss: 0.0078 - val_accuracy: 0.9980\n",
            "Q 305+536 T 841  \u001b[92m☑\u001b[0m 841 \n",
            "Q 58+73   T 131  \u001b[92m☑\u001b[0m 131 \n",
            "Q 80+80   T 160  \u001b[92m☑\u001b[0m 160 \n",
            "Q 30+110  T 140  \u001b[92m☑\u001b[0m 140 \n",
            "Q 711+92  T 803  \u001b[92m☑\u001b[0m 803 \n",
            "Q 896+6   T 902  \u001b[92m☑\u001b[0m 902 \n",
            "Q 16+52   T 68   \u001b[92m☑\u001b[0m 68  \n",
            "Q 775+15  T 790  \u001b[92m☑\u001b[0m 790 \n",
            "Q 92+90   T 182  \u001b[92m☑\u001b[0m 182 \n",
            "Q 70+60   T 130  \u001b[92m☑\u001b[0m 130 \n",
            "\n",
            "Iteration 34\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0216 - accuracy: 0.9941 - val_loss: 0.0081 - val_accuracy: 0.9984\n",
            "Q 79+43   T 122  \u001b[92m☑\u001b[0m 122 \n",
            "Q 336+37  T 373  \u001b[92m☑\u001b[0m 373 \n",
            "Q 331+983 T 1314 \u001b[92m☑\u001b[0m 1314\n",
            "Q 391+409 T 800  \u001b[91m☒\u001b[0m 700 \n",
            "Q 213+860 T 1073 \u001b[92m☑\u001b[0m 1073\n",
            "Q 48+376  T 424  \u001b[92m☑\u001b[0m 424 \n",
            "Q 59+432  T 491  \u001b[92m☑\u001b[0m 491 \n",
            "Q 368+929 T 1297 \u001b[92m☑\u001b[0m 1297\n",
            "Q 79+51   T 130  \u001b[92m☑\u001b[0m 130 \n",
            "Q 569+630 T 1199 \u001b[92m☑\u001b[0m 1199\n",
            "\n",
            "Iteration 35\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
            "Q 33+646  T 679  \u001b[92m☑\u001b[0m 679 \n",
            "Q 273+218 T 491  \u001b[92m☑\u001b[0m 491 \n",
            "Q 391+235 T 626  \u001b[92m☑\u001b[0m 626 \n",
            "Q 894+997 T 1891 \u001b[92m☑\u001b[0m 1891\n",
            "Q 93+422  T 515  \u001b[92m☑\u001b[0m 515 \n",
            "Q 591+84  T 675  \u001b[92m☑\u001b[0m 675 \n",
            "Q 532+78  T 610  \u001b[92m☑\u001b[0m 610 \n",
            "Q 94+381  T 475  \u001b[92m☑\u001b[0m 475 \n",
            "Q 191+583 T 774  \u001b[92m☑\u001b[0m 774 \n",
            "Q 6+897   T 903  \u001b[92m☑\u001b[0m 903 \n",
            "\n",
            "Iteration 36\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
            "Q 2+205   T 207  \u001b[92m☑\u001b[0m 207 \n",
            "Q 93+343  T 436  \u001b[92m☑\u001b[0m 436 \n",
            "Q 458+73  T 531  \u001b[92m☑\u001b[0m 531 \n",
            "Q 733+96  T 829  \u001b[92m☑\u001b[0m 829 \n",
            "Q 216+952 T 1168 \u001b[92m☑\u001b[0m 1168\n",
            "Q 642+16  T 658  \u001b[92m☑\u001b[0m 658 \n",
            "Q 679+255 T 934  \u001b[92m☑\u001b[0m 934 \n",
            "Q 308+14  T 322  \u001b[92m☑\u001b[0m 322 \n",
            "Q 966+388 T 1354 \u001b[92m☑\u001b[0m 1354\n",
            "Q 867+91  T 958  \u001b[92m☑\u001b[0m 958 \n",
            "\n",
            "Iteration 37\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0116 - val_accuracy: 0.9964\n",
            "Q 134+84  T 218  \u001b[92m☑\u001b[0m 218 \n",
            "Q 375+441 T 816  \u001b[92m☑\u001b[0m 816 \n",
            "Q 30+763  T 793  \u001b[92m☑\u001b[0m 793 \n",
            "Q 125+86  T 211  \u001b[92m☑\u001b[0m 211 \n",
            "Q 209+46  T 255  \u001b[92m☑\u001b[0m 255 \n",
            "Q 41+394  T 435  \u001b[92m☑\u001b[0m 435 \n",
            "Q 948+8   T 956  \u001b[92m☑\u001b[0m 956 \n",
            "Q 350+12  T 362  \u001b[92m☑\u001b[0m 362 \n",
            "Q 942+833 T 1775 \u001b[92m☑\u001b[0m 1775\n",
            "Q 333+505 T 838  \u001b[92m☑\u001b[0m 838 \n",
            "\n",
            "Iteration 38\n",
            "1108/1407 [======================>.......] - ETA: 1s - loss: 0.0366 - accuracy: 0.9895"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1733d1360fb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m               validation_data=(x_val, y_val))\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Select 10 samples from the validation set at random so we can visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    850\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MT9sLhYozBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}