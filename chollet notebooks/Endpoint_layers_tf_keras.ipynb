{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Endpoint layers tf.keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsBSCufaC71Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0aK1hHM9SmL",
        "colab_type": "code",
        "outputId": "2840ce57-b077-4b54-99ad-88b8e59d2e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0-rc3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCsztpDc9Wr5",
        "colab_type": "text"
      },
      "source": [
        "# Usage of endpoint layers in the Functional API\n",
        "\n",
        "An \"endpoint layer\" has access to the model's targets, and creates arbitrary losses and metrics using `add_loss` and `add_metric`. This enables you to define losses and metrics that don't match the usual signature `fn(y_true, y_pred, sample_weight=None)`.\n",
        "\n",
        "Note that you could have separate metrics for training and eval with this pattern."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2HH1TUkmtCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticEndpoint(keras.layers.Layer):\n",
        "  def __init__(self, name=None):\n",
        "    super(LogisticEndpoint, self).__init__(name=name)\n",
        "    self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    self.accuracy_fn = keras.metrics.BinaryAccuracy(name='accuracy')\n",
        "\n",
        "  def call(self, logits, targets=None, sample_weight=None):\n",
        "    if targets is not None:\n",
        "        # Compute the training-time loss value and add it\n",
        "        # to the layer using `self.add_loss()`.\n",
        "        loss = self.loss_fn(targets, logits, sample_weight)\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        # Log the accuracy as a metric (we could log arbitrary metrics,\n",
        "        # including different metrics for training and inference).\n",
        "        self.add_metric(self.accuracy_fn(targets, logits, sample_weight))\n",
        "\n",
        "    # Return the inference-time prediction tensor (for `.predict()`).\n",
        "    return tf.nn.softmax(logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZh-iJWP9Ttp",
        "colab_type": "code",
        "outputId": "0a82d149-65f2-4200-8e5f-f22de6dba8a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "inputs = keras.Input((764,), name='inputs')\n",
        "logits = keras.layers.Dense(1)(inputs)\n",
        "targets = keras.Input((1,), name='targets')\n",
        "sample_weights = keras.Input((1,), name='sample_weights')\n",
        "preds = LogisticEndpoint()(targets, logits, sample_weights)\n",
        "model = keras.Model([inputs, targets, sample_weights], preds)\n",
        "\n",
        "data = {\n",
        "    'inputs': np.random.random((1000, 764)),\n",
        "    'targets': np.random.random((1000, 1)),\n",
        "    'sample_weights': np.random.random((1000, 1))\n",
        "}\n",
        "\n",
        "model.compile(keras.optimizers.Adam(1e-3))\n",
        "model.fit(data, epochs=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "32/32 [==============================] - 0s 1ms/step - loss: -0.8189 - accuracy: 0.0000e+00\n",
            "Epoch 2/2\n",
            "32/32 [==============================] - 0s 1ms/step - loss: -3.9466 - accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wos2VWhEcPTB",
        "colab_type": "text"
      },
      "source": [
        "## Exporting an inference-only model\n",
        "\n",
        "Simply don't include `targets` in the model. The weights stay the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfc5tSEccOkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = keras.Input((764,), name='inputs')\n",
        "logits = keras.layers.Dense(1)(inputs)\n",
        "preds = LogisticEndpoint()(logits, targets=None, sample_weight=None)\n",
        "inference_model = keras.Model(inputs, preds)\n",
        "\n",
        "inference_model.set_weights(model.get_weights())\n",
        "\n",
        "preds = inference_model.predict(np.random.random((1000, 764)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHGlOMCnAZEk",
        "colab_type": "text"
      },
      "source": [
        "# Usage of loss endpoint layers in subclassed models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F45uB239gIf",
        "colab_type": "code",
        "outputId": "54f149a0-5c76-4064-fb48-1d45434fc172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "class LogReg(keras.Model):\n",
        "  def __init__(self):\n",
        "    super(LogReg, self).__init__()\n",
        "    self.dense = keras.layers.Dense(1)\n",
        "    self.logistic_endpoint = LogisticEndpoint()\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # Note that all inputs should be in the first argument\n",
        "    # since we want to be able to call `model.fit(inputs)`.\n",
        "    logits = self.dense(inputs['inputs'])\n",
        "    preds = self.logistic_endpoint(logits=logits,\n",
        "                                   targets=inputs['targets'],\n",
        "                                   sample_weight=inputs['sample_weight'])\n",
        "    return preds\n",
        "\n",
        "model = LogReg()\n",
        "data = {\n",
        "    'inputs': np.random.random((1000, 764)),\n",
        "    'targets': np.random.random((1000, 1)),\n",
        "    'sample_weight': np.random.random((1000, 1))\n",
        "}\n",
        "\n",
        "model.compile(keras.optimizers.Adam(1e-3))\n",
        "model.fit(data, epochs=2)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.3529 - accuracy: 0.0000e+00\n",
            "Epoch 2/2\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.3545 - accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb9c1d2a0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZXSFqYYbA8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}